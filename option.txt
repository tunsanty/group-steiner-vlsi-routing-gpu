--report-bindings
-map-by core -map-by node
-bind-to core



currenlty processes are not bound to any core that means even though they
star off running on a single core, they might potentially migrated  around
between cores by the process scheduleer inorder to keep the processing resources
equally busy. 

http://blogs.cisco.com/performance/open-mpi-binding-to-core-by-default

for some reason code was returned wrong cost if # of processors was above 6, i
thougt it had something to do with the way the processes get assigned to the
processors but it turned out it was because MPI_Ibcast wasnt finishing its job
in time for using the metric closure. I should have used MPI-wait.
if without MPI_wait, there might be data communication lag and we might try to
work with data that hasnt arrived yet 
